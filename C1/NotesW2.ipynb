{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NotesW2.ipynb","provenance":[],"authorship_tag":"ABX9TyMdO7IHF3L4/k0DjgoYxqcH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Introduction to computer Vision \n","\n","Is the field of having a computer understand and label what is present in an image. \n","\n","One way to solve that is use lots of pictures of clothing and tell the computer what that is a picture of and then have the computer to give the standard that give you the difference between a shoe and a shirt etc. \n","\n","Usally the smaller the better because the computer has less processing to do. Same thing to gray scale.\n","\n","Machine Learning depends on having good data to train a system with.EX: dataset called Fashion MNIST(https://github.com/zalandoresearch/fashion-mnist).\n","\n","Here you saw how the data can be loaded into Python data structures that make it easy to train a neural network. You saw how the image is represented as a 28x28 array of greyscales, and how its label is a number. Using a number is a first step in avoiding bias -- instead of labelling it with words in a specific language and excluding people who don’t speak that language! (https://ai.google/responsibilities/responsible-ai-practices/).\n","\n","You'll notice that all of the values in the number are between 0 and 255. If you are training a neural network especially in image processing, for various reasons it will usually learn better if you scale all values to between 0 and 1. It's a process called normalization and fortunately in Python, it's easy to normalize an array without looping.\n","\n","Sequential: That defines a sequence of layers in the neural network.\n","\n","Flatten: Remember earlier where our images were a 28x28 pixel matrix when you printed them out? Flatten just takes that square and turns it into a 1-dimensional array.\n","\n","Dense: Adds a layer of neurons\n","\n","# How to Load Data\n","\n","When using a dataset is a good pratice use part to train part to test. \n","\n","Important to loof for the first and last layers. \n","- 10 Neurons: 10 classes\n","- First layers: Indicates the shape we should expect the data to be in.\n","- Flatten takes this 28 by 28 square and turns into a simple linear array. \n","\n","REF:https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/main/C1/W2/ungraded_labs/C1_W2_Lab_1_beyond_hello_world.ipynb"],"metadata":{"id":"hIrUpX6GD4gg"}},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow import keras\n","from tensorflow.keras import layers \n","\n","if __name__ == \"__main__\":\n","  #Load the fashion MNIST dataset\n","  fashion_mnist = tf.keras.datasets.fashion_mnist\n","  #Load the training and test split of the fashion MNIST dataset\n","  (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n","\n","  # Normalize the pixel values of the train and test images\n","  train_images  = train_images / 255.0\n","  test_images = test_images / 255.0\n","\n","  model = keras.Sequential([\n","    keras.layers.Flatten(input_shape=(28,28)),\n","    keras.layers.Dense(128, activation=tf.nn.relu),\n","    keras.layers.Dense(10, activation=tf.nn.softmax) #10 -> Number of types of clothes. Always must match                 \n","  ])\n","\n","  # Declare sample inputs and convert to a \n","  #Tensores são entidades geométricas introduzidas na matemática e na física para generalizar a noção de escalares, \n","  #vetores e matrizes. Assim como tais entidades, um tensor é uma forma de representação associada a um conjunto de \n","  #operações tais como a soma e o produto.\n","  #Ta fazendo nada esse código\n","  # inputs = np.array([[1.0, 2.0, 3.0, 4.0]])\n","  # inputs = tf.convert_to_tensor(inputs)\n","  # print(f'input to softmax function: {inputs.numpy()}')\n","\n","  # # Feed the inputs to a softmax activation function\n","  # outputs = tf.keras.activations.softmax(inputs)\n","  # print(f'output of softmax function: {outputs.numpy()}')\n","\n","  # # Get the sum of all values after the softmax\n","  # sum = tf.reduce_sum(outputs)\n","  # print(f'sum of outputs: {sum}')\n","\n","  # # Get the index with highest value\n","  # prediction = np.argmax(outputs)\n","  # print(f'class with highest probability: {prediction}')\n","\n","  model.compile(optimizer = tf.optimizers.Adam(),\n","              loss = 'sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","  model.fit(train_images, train_labels, epochs=5)\n","\n","  # Evaluate the model on unseen data\n","  model.evaluate(test_images, test_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KwdIVSH2GRsO","executionInfo":{"status":"ok","timestamp":1653954840200,"user_tz":180,"elapsed":22339,"user":{"displayName":"José Gomes","userId":"01262789703936421045"}},"outputId":"ea5e7152-d04f-4521-ba7f-1027d5637f78"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.5008 - accuracy: 0.8244\n","Epoch 2/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3725 - accuracy: 0.8671\n","Epoch 3/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3360 - accuracy: 0.8766\n","Epoch 4/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3127 - accuracy: 0.8857\n","Epoch 5/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2957 - accuracy: 0.8908\n","313/313 [==============================] - 1s 1ms/step - loss: 0.3432 - accuracy: 0.8782\n"]}]},{"cell_type":"markdown","source":["# Activation Function\n","\n","First we have some input data that we have got a vectorize then we feed it into the network, which means we basically perform a series of matrix operations on this input layer by layer. \n","\n","Activation functions introduce nonlinear properties to our network so we can call them nonlinearities. "],"metadata":{"id":"Vtxb03n1UavN"}},{"cell_type":"markdown","source":[""],"metadata":{"id":"cXDniYkBHqZa"}},{"cell_type":"code","source":["#Exercício \n","# For this first exercise run the below code: It creates a set of classifications for each of the test images, \n","# and then prints the first entry in the classifications. The output, after you run it is a list of numbers. \n","# Why do you think this is, and what do those numbers represent?\n","\n","import tensorflow as tf\n","import numpy as np\n","from tensorflow import keras\n","from tensorflow.keras import layers \n","\n","if __name__ == \"__main__\":\n","  #Load the fashion MNIST dataset\n","  fashion_mnist = tf.keras.datasets.fashion_mnist\n","  #Load the training and test split of the fashion MNIST dataset\n","  (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n","\n","  # Normalize the pixel values of the train and test images\n","  train_images  = train_images / 255.0\n","  test_images = test_images / 255.0\n","\n","  model = keras.Sequential([\n","    keras.layers.Flatten(input_shape=(28,28)),\n","    keras.layers.Dense(128, activation=tf.nn.relu),\n","    keras.layers.Dense(10, activation=tf.nn.softmax) #10 -> Number of types of clothes. Always must match                 \n","  ])\n","  \n","  model.compile(optimizer = tf.optimizers.Adam(),\n","              loss = 'sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","  model.fit(train_images, train_labels, epochs=5)\n","\n","  #Probability for each class\n","  classifications = model.predict(test_images)\n","  print(classifications[0])\n","  # # Evaluate the model on unseen data\n","  # model.evaluate(test_images, test_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Yamb3bBZEBK","executionInfo":{"status":"ok","timestamp":1653954969725,"user_tz":180,"elapsed":21945,"user":{"displayName":"José Gomes","userId":"01262789703936421045"}},"outputId":"09ed01f8-a8fb-4a79-bd4d-a4fa16ca17c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.4962 - accuracy: 0.8261\n","Epoch 2/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3713 - accuracy: 0.8657\n","Epoch 3/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3331 - accuracy: 0.8784\n","Epoch 4/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3108 - accuracy: 0.8867\n","Epoch 5/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2938 - accuracy: 0.8921\n","[9.0076965e-06 9.4153899e-07 3.3565334e-07 3.0207516e-07 9.5728683e-07\n"," 6.3280767e-04 1.2219220e-05 2.6937641e-02 1.0121847e-04 9.7230452e-01]\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"eYANeqaraiuR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Callbacks\n","\n","How can i stop training when i reach a point that i want to be at?\n","The training loop does support callbacks. \n","(https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/main/C1/W2/ungraded_labs/C1_W2_Lab_2_callbacks.ipynb)"],"metadata":{"id":"JNO5S1OTah7C"}},{"cell_type":"code","source":["#Exercício \n","# For this first exercise run the below code: It creates a set of classifications for each of the test images, \n","# and then prints the first entry in the classifications. The output, after you run it is a list of numbers. \n","# Why do you think this is, and what do those numbers represent?\n","\n","import tensorflow as tf\n","# import numpy as np\n","# from tensorflow import keras\n","# from tensorflow.keras import layers \n","\n","class myCallback(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs={}):\n","    if(logs.get('loss')<0.4):\n","      print('\\nLoss is low so canceling the training!')\n","      self.model.stop_training = True\n","\n","if __name__ == \"__main__\":\n","  callbacks = myCallback()\n","  #Load the fashion MNIST dataset\n","  fashion_mnist = tf.keras.datasets.fashion_mnist\n","  #Load the training and test split of the fashion MNIST dataset\n","  (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n","\n","  # Normalize the pixel values of the train and test images\n","  train_images  = train_images / 255.0\n","  test_images = test_images / 255.0\n","\n","  model = keras.Sequential([\n","    keras.layers.Flatten(input_shape=(28,28)),\n","    keras.layers.Dense(512, activation=tf.nn.relu),\n","    keras.layers.Dense(10, activation=tf.nn.softmax) #10 -> Number of types of clothes. Always must match                 \n","  ])\n","  \n","  model.compile(optimizer = tf.optimizers.Adam(),\n","              loss = 'sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","  model.fit(train_images, train_labels, epochs=5, callbacks=[callbacks])\n","\n","  # #Probability for each class\n","  # classifications = model.predict(test_images)\n","  # print(classifications[0])\n","  # # # Evaluate the model on unseen data\n","  # # model.evaluate(test_images, test_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uAK__BoD3udg","executionInfo":{"status":"ok","timestamp":1654013576419,"user_tz":180,"elapsed":18401,"user":{"displayName":"José Gomes","userId":"01262789703936421045"}},"outputId":"e10d7c66-24ab-4497-c81d-f104b1cc231f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.4724 - accuracy: 0.8315\n","Epoch 2/5\n","1866/1875 [============================>.] - ETA: 0s - loss: 0.3567 - accuracy: 0.8691\n","Loss is low so canceling the training!\n","1875/1875 [==============================] - 8s 5ms/step - loss: 0.3567 - accuracy: 0.8691\n"]}]}]}