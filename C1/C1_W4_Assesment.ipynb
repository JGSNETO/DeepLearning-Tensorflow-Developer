{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"C1_W4_Assesment.ipynb","provenance":[],"authorship_tag":"ABX9TyOArJQrESJJWTblLmP3vtbV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"mTcf1Wpet3fV"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import numpy as np\n","import os\n","\n","from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import optimizers, losses\n","from tensorflow.keras.optimizers import RMSprop\n","\n","\n","base_dir = \"./data/\"\n","happy_dir = os.path.join(base_dir, \"happy/\")\n","sad_dir = os.path.join(base_dir, \"sad/\")\n","\n","print(\"Sample happy image:\")\n","plt.imshow(load_img(f\"{os.path.join(happy_dir, os.listdir(happy_dir)[0])}\"))\n","plt.show()\n","\n","print(\"\\nSample sad image:\")\n","plt.imshow(load_img(f\"{os.path.join(sad_dir, os.listdir(sad_dir)[0])}\"))\n","plt.show()\n","\n","\n","# Load the first example of a happy face\n","sample_image  = load_img(f\"{os.path.join(happy_dir, os.listdir(happy_dir)[0])}\")\n","\n","# Convert the image into its numpy array representation\n","sample_array = img_to_array(sample_image)\n","\n","print(f\"Each image has shape: {sample_array.shape}\")\n","\n","print(f\"The maximum pixel value used is: {np.max(sample_array)}\")\n","\n","class myCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs={}):\n","        if logs.get('accuracy') is not None and logs.get('accuracy') > 0.999:\n","            print(\"\\nReached 99.9% accuracy so cancelling training!\")\n","            self.model.stop_training = True\n","\n","# GRADED FUNCTION: image_generator\n","def image_generator():\n","    ### START CODE HERE\n","\n","    # Instantiate the ImageDataGenerator class.\n","    # Remember to set the rescale argument.\n","    train_datagen = ImageDataGenerator(rescale=1/255)\n","\n","    # Specify the method to load images from a directory and pass in the appropriate arguments:\n","    # - directory: should be a relative path to the directory containing the data\n","    # - targe_size: set this equal to the resolution of each image (excluding the color dimension)\n","    # - batch_size: number of images the generator yields when asked for a next batch. Set this to 10.\n","    # - class_mode: How the labels are represented. Should be one of \"binary\", \"categorical\" or \"sparse\".\n","    #               Pick the one that better suits here given that the labels are going to be 1D binary labels.\n","    train_generator = train_datagen.flow_from_directory(directory='./data/',\n","                                                        target_size=(150, 150),\n","                                                        batch_size=128,\n","                                                        class_mode='binary')\n","    ### END CODE HERE\n","\n","    return train_generator\n","\n","# Save your generator in a variable\n","gen = image_generator()\n","\n","# GRADED FUNCTION: train_happy_sad_model\n","def train_happy_sad_model(train_generator):\n","\n","    # Instantiate the callback\n","    callbacks = myCallback()\n","\n","    ### START CODE HERE\n","\n","    # Define the model\n","    model = tf.keras.models.Sequential([\n","        # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n","        # This is the first convolution\n","        tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n","        tf.keras.layers.MaxPooling2D(2, 2),\n","        # The second convolution\n","        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n","        tf.keras.layers.MaxPooling2D(2,2),\n","        # The third convolution\n","        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","        tf.keras.layers.MaxPooling2D(2,2),\n","        # Flatten the results to feed into a DNN\n","        tf.keras.layers.Flatten(),\n","        # 512 neuron hidden layer\n","        tf.keras.layers.Dense(512, activation='relu'),\n","        # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n","        tf.keras.layers.Dense(1, activation='sigmoid')\n","    ])\n","\n","    # Compile the model\n","    # Select a loss function compatible with the last layer of your network\n","    model.compile(loss='binary_crossentropy',\n","                  optimizer= RMSprop(learning_rate=0.001),\n","                  metrics=['accuracy']) \n","    \n","\n","\n","    # Train the model\n","    # Your model should achieve the desired accuracy in less than 15 epochs.\n","    # You can hardcode up to 20 epochs in the function below but the callback should trigger before 15.\n","    history = model.fit(train_generator,\n","                        epochs=20,\n","                        callbacks= [callbacks]\n","                       ) \n","    \n","    ### END CODE HERE\n","    return history\n","    \n","hist = train_happy_sad_model(gen)"]}]}