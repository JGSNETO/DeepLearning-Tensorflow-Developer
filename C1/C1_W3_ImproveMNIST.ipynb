{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"C1_W3_ImproveMNIST.ipynb","provenance":[],"authorship_tag":"ABX9TyPbZoMfAmnmrYi6GJHZlEHa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"GLxR_OVMZ8Qn"},"outputs":[],"source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","# Load the data\n","\n","# Get current working directory\n","current_dir = os.getcwd() \n","\n","# Append data/mnist.npz to the previous path to get the full path\n","data_path = os.path.join(current_dir, \"data/mnist.npz\") \n","\n","# Get only training set\n","(training_images, training_labels), _ = tf.keras.datasets.mnist.load_data(path=data_path) \n","\n","# GRADED FUNCTION: reshape_and_normalize\n","\n","def reshape_and_normalize(images):\n","    \n","    ### START CODE HERE\n","\n","    # Reshape the images to add an extra dimension\n","    #images = np.reshape(1,1)\n","    \n","    # Normalize pixel values\n","    images = images/255\n","    \n","    ### END CODE HERE\n","\n","    return images\n","\n","# Reload the images in case you run this cell multiple times\n","(training_images, _), _ = tf.keras.datasets.mnist.load_data(path=data_path) \n","\n","# Apply your function\n","training_images = reshape_and_normalize(training_images)\n","\n","print(f\"Maximum pixel value after normalization: {np.max(training_images)}\\n\")\n","print(f\"Shape of training set after reshaping: {training_images.shape}\\n\")\n","print(f\"Shape of one image after reshaping: {training_images[0].shape}\")\n","\n","# GRADED CLASS: myCallback\n","### START CODE HERE\n","\n","# Remember to inherit from the correct class\n","class myCallback(tf.keras.callbacks.Callback):\n","    # Define the method that checks the accuracy at the end of each epoch\n","    def on_epoch_end(self, epoch, logs={}):\n","        if logs.get('accuracy') > 0.99:\n","            print('\\nReach 99% accuracy so cancelling training!')\n","            self.model.stop_training = True\n","\n","### END CODE HERE\n","\n","# GRADED FUNCTION: convolutional_model\n","def convolutional_model():\n","    ### START CODE HERE\n","\n","    # Define the model\n","    model = tf.keras.models.Sequential([ \n","        \n","        tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)), #Generate 64 filters for us. 3x3, relu(negaive value will be discard), input shape, 2 single bit for color depth.\n","        tf.keras.layers.MaxPooling2D(2,2), #Pooling layer. Max because we going to take the maximum value. 2x2 pool. To each 4 pixels 1 will survive. \n","        #Repetiu a camada para que o sistema possa aprender novamente em cima da nova camada criada anteriormente. \n","        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","        tf.keras.layers.MaxPooling2D(2,2),\n","        tf.keras.layers.Flatten(),\n","        tf.keras.layers.Dense(128, activation=tf.nn.relu),\n","        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n","        \n","    ]) \n","\n","    ### END CODE HERE\n","\n","    # Compile the model\n","    model.compile(optimizer='adam', \n","                  loss='sparse_categorical_crossentropy', \n","                  metrics=['accuracy']) \n","        \n","    return model\n","\n","  # Save your untrained model\n","model = convolutional_model()\n","\n","# Instantiate the callback class\n","callbacks = myCallback()\n","\n","# Train your model (this can take up to 5 minutes)\n","history = model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])"]}]}